---
layout: default
title: The Supervised Machine Learning book
tagline: Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten and Thomas B. Schön
description: An upcoming textbook on the essentials of supervised machine learning
---

When we developed the course [Statistical Machine Learning](http://www.it.uu.se/edu/course/homepage/sml/) for engineering students at Uppsala University, we found no appropriate textbook, so we ended up writing our own. It will eventually be published by Cambridge University Press.

[Andreas Lindholm](http://www.it.uu.se/katalog/andsv164/),
[Niklas Wahlström](https://www.it.uu.se/katalog/nikwa778/),
[Fredrik Lindsten](https://liu.se/medarbetare/freli29), and
[Thomas B. Schön](http://user.it.uu.se/~thosc112/)

A draft of the book will soon be available on this page. **We will keep a PDF of the book freely available also after publication.**


## The book

**Table of Contents**

1. **Introduction**
2. **Supervised machine learning: a first approach**
   - Supervised learning
   - A distance-based method: k-NN
   - A rule-based method: Decision trees
3. **Basic parametric models for regression and classification**
   - Linear regression
   - Logistic regression
   - Nonlinear input transformations and regularization
   - Nonlinear parametric models
4. **Understanding, evaluating and improving the performance**
   - Expected new data error: performance in production
   - Estimating the expected new data error
   - The training error–generalization gap decomposition
   - The bias-variance decomposition
   - Evaluation for imbalanced and asymmetric classification problems
5. **Learning parametric models: regularization, loss functions and optimization**
   - Regularization
   - Loss functions
   - Parameter optimization
   - Optimization with large datasets
6. **Neural networks and deep learning**
   - Neural networks
   - Convolutional neural networks
   - Training a neural network
7. **Ensemble methods: Bagging and boosting**
   - Bagging
   - Random forests
   - Boosting and AdaBoost
   - Gradient boosting
8. **Nonlinear input transformations and kernels**
   - Creating features by nonlinear input transformations
   - The kernel trick in linear regression and support vector regression
   - Kernel k-NN and kernel theory
   - Support vector classification
9. **The Bayesian approach and Gaussian processes**
   - Bayesian linear regression
   - Gaussian processes
10. **User aspects of machine learning**
    - Defining the machine learning problem
    - The iterative process of improving a machine learning model
    - Data collection and preparation
    - End-to-end learning vs. feature engineering
    - Can I trust my machine learning model?
    - Ethics in machine learning
11. **Generative models and learning from unlabeled data**
    - Generative models: LDA, QDA and more
    - Semi-supervised and self-supervised learning
    - Unsupervised learning

[**Latest draft of the book**](book/sml-book.pdf) (soon to be put online)


## Exercise material

Will eventually be added to this page. Meanwhile you may have a look at the material for our [course at Uppsala University](http://www.it.uu.se/edu/course/homepage/sml/) (exercise material will be available at the course beginning in January).

## [Report mistakes and give feedback](https://github.com/uu-sml/sml-book-page/issues)
(A free GitHub account is required)
